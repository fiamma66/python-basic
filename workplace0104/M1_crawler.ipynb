{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time,re\n",
    "import random , logstash , logging , pymongo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "host = '192.168.114.130'\n",
    "client = \"mongodb://\" + host + \":27017/\"\n",
    "# 多執行續下 可能被 dead lock \n",
    "myclient = pymongo.MongoClient(client, connect=False)\n",
    "mydb = myclient[\"mydatabase\"]\n",
    "mycol = mydb[\"Mobile01\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"我們都很好Pleas =======\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我們都很好Pleas'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"\\W+\",\"\",s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我們都很好Pleas ======='"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline \n",
    "logger = logging.getLogger('python-logstash-logger')\n",
    "logger.setLevel(logging.INFO)\n",
    "host_demo = \"logstash\"\n",
    "logger.addHandler(logstash.TCPLogstashHandler(host_demo,5959))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.mobile01.com/waypointlist.php?list=1&c=0&s=desc&p=1\"\n",
    "\n",
    "def get_url(n=2,m=3):\n",
    "    result = []\n",
    "    # 增加直覺 從第n頁 到 第m頁\n",
    "    m = m + 1\n",
    "    for t in range(n,m):\n",
    "        url = \"https://www.mobile01.com/waypointlist.php?list=1&c=0&s=desc&p=\" + str(t)\n",
    "        result.append(url)\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxylist = [{\"http\": \"37.187.120.123:80\"},\n",
    "             {\"https\": \"206.189.36.198:8080\"},\n",
    "             {\"https\": \"178.128.31.153:8080\"},\n",
    "             {\"http\": \"167.114.180.102:8080\"},\n",
    "             {\"http\": \"104.131.214.218:80\"},\n",
    "             {\"http\": \"167.114.196.153:80\"}]\n",
    "header = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'}\n",
    "\n",
    "class Connect404Except(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_connect(url):\n",
    "    i = 0\n",
    "    \n",
    "    while True :\n",
    "        \n",
    "        try :\n",
    "            resp = requests.get(url,headers=header,proxies=proxylist[i])          \n",
    "            resp.encoding = \"utf-8\"\n",
    "            time.sleep(random.randint(1,4))\n",
    "           \n",
    "            \n",
    "        except requests.exceptions.ConnectionError :             \n",
    "            #logger.warning(\"Proxy Error\",extra={\"proxy\":proxylist[i]})\n",
    "            \n",
    "            i = (i + 1) % 6\n",
    "            continue\n",
    "\n",
    "            \n",
    "            \n",
    "        if resp : \n",
    "            if resp.status_code == 200 :\n",
    "                code = \"HTTP response code = \" + str(resp.status_code)\n",
    "                #logger.info(code,extra={\"url\" : url, \"time_use\" : resp.elapsed.total_seconds()})\n",
    "                #print(proxylist[i])\n",
    "                break         \n",
    "        if resp.status_code == 404 :\n",
    "            #logger.warning(\"This page is gone nowhere !\",extra={\"url\":url})\n",
    "                \n",
    "            break\n",
    "        \n",
    "        \n",
    "    return resp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(urls):\n",
    "    result = []\n",
    "    \n",
    "    connect = get_connect(urls)\n",
    "    try :\n",
    "        if connect.status_code == 404:\n",
    "            raise Connect404Except\n",
    "            \n",
    "        else :\n",
    "            soup = BeautifulSoup(connect.text)\n",
    "            \n",
    "    except Connect404Except : \n",
    "        logger.error(\"index error\",extra={\"index\":urls})\n",
    "        pass\n",
    "    \n",
    "    if soup :\n",
    "        print(\"進入\",urls)\n",
    "        table = soup.find_all(\"tr\")\n",
    "        # 取得列表內容\n",
    "        for t in table:\n",
    "            title = t.find(\"p\", class_=\"title\").text\n",
    "            href = \"https://www.mobile01.com/\" + t.find(\"p\", class_=\"title\").find(\"a\")[\"href\"]\n",
    "            sp = t.find(\"p\", class_=\"info\").text.split(\"-\")[1].replace(\" \",\"\")\n",
    "            date = t.find(\"p\", class_=\"info\").text.split(\":\")[2].split(\" \")[1]\n",
    "            \n",
    "            # 進入第二層 遊記 去除風景\n",
    "            if \"餐飲\" in sp:\n",
    "                print(\"現在處理:\",href)\n",
    "                conn = get_connect(href)\n",
    "                try :\n",
    "                    if conn.status_code == 404:\n",
    "                        raise Connect404Except\n",
    "\n",
    "                    else :\n",
    "                        art = BeautifulSoup(conn.text)\n",
    "\n",
    "                except Connect404Except : \n",
    "                    logger.error(\"page error\",extra={\"index\":href})\n",
    "                    continue\n",
    "                content = art.find(\"div\", class_=\"single-post-content\").text.replace(\"\\r\",\"\").replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "                img_url = []\n",
    "                imgs = art.find(\"div\", class_=\"single-post-content\").find_all(\"img\")\n",
    "                for img in imgs:\n",
    "                    img_url.append(img[\"data-src\"])\n",
    "                author = soup.find(\"div\", class_=\"panel note sidebar-authur\").find(\"a\").text\n",
    "                article_hit = soup.find_all(\"div\",class_=\"panel note\")[1].find_all(\"li\")[0].text.split(\":\")[-1]\n",
    "                rate = soup.find_all(\"div\",class_=\"panel note\")[1].find_all(\"li\")[1].text.split(\":\")[-1]\n",
    "                res_info = get_res_info(art)\n",
    "                # 進入第三層 評論\n",
    "                comment_url = \"https://www.mobile01.com/\" + soup.find(\"div\", class_=\"btns wide\").find(\"a\")[\"href\"]\n",
    "                new_conn = BeautifulSoup(get_connect(comment_url).text)\n",
    "                comment = get_comment(new_conn)\n",
    "                if art.find(\"div\", class_=\"pagination\").find(\"a\").text == \"下一頁\"\n",
    "                \n",
    "                    \n",
    "                        \n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find_all(\"tr\")\n",
    "table[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table[0].find(\"p\", class_=\"info\").text.split(\"-\")[1].replace(\" \",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得列表內容\n",
    "for t in table:\n",
    "    title = t.find(\"p\", class_=\"title\").text\n",
    "    href = \"https://www.mobile01.com/\" + t.find(\"p\", class_=\"title\").find(\"a\")[\"href\"]\n",
    "    sp = t.find(\"p\", class_=\"info\").text.split(\"-\")[1].replace(\" \",\"\")\n",
    "    date = t.find(\"p\", class_=\"info\").text.split(\":\")[2].split(\" \")[1]\n",
    "    print(\"title : \",title)\n",
    "    print(\"href : \",href)\n",
    "    print(\"sp : \",sp)\n",
    "    print(\"date : \",date)\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "href = \"https://www.mobile01.com/waypointdetail.php?id=32490\"\n",
    "soup = BeautifulSoup(get_connect(href).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文章本文\n",
    "content = soup.find(\"div\", class_=\"single-post-content\").text.replace(\"\\r\",\"\").replace(\"\\n\",\"\").replace(\" \",\"\")\n",
    "img_url = []\n",
    "imgs = soup.find(\"div\", class_=\"single-post-content\").find_all(\"img\")\n",
    "for img in imgs:\n",
    "        img_url.append(img[\"data-src\"])\n",
    "author = soup.find(\"div\", class_=\"panel note sidebar-authur\").find(\"a\").text\n",
    "article_hit = soup.find_all(\"div\",class_=\"panel note\")[1].find_all(\"li\")[0].text.split(\":\")[-1]\n",
    "rate = soup.find_all(\"div\",class_=\"panel note\")[1].find_all(\"li\")[1].text.split(\":\")[-1]\n",
    "res_info = get_res_info(soup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 餐廳資訊 評等\n",
    "def get_res_info(soup):\n",
    "    res_info = []\n",
    "    info = soup.find(id=\"info_form\")\n",
    "    \n",
    "    rate = len(info.find_all(\"div\")[8].find_all(\"img\"))\n",
    "    place = info.find_all(\"div\")[1].text.replace(\"\\n\",\"\").replace(\" \",\"\").split(\":\")[-1]\n",
    "    phone = info.find_all(\"div\")[2].text.replace(\"\\n\",\"\").replace(\" \",\"\").split(\":\")[-1]\n",
    "    op_time = info.find_all(\"div\")[3].text.replace(\"\\n\",\"\").split(\"  \")[-1]\n",
    "    point = info.find_all(\"div\")[7].text.replace(\"\\n\",\"\").replace(\" \",\"\").split(\":\")[-1]\n",
    "    res_info.append({\n",
    "        \"rate\" : rate,\n",
    "        \"place\" : place,\n",
    "        \"phone\" : phone,\n",
    "        \"op_time\" : op_time,\n",
    "        \"point\" : point\n",
    "    })\n",
    "    return res_info\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_url = \"https://www.mobile01.com/\" + soup.find(\"div\", class_=\"btns wide\").find(\"a\")[\"href\"]\n",
    "\n",
    "comment_soup = BeautifulSoup(get_connect(comment_url).text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_comment(comment_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = []\n",
    "for single_comment in comment_soup.find_all(\"article\")[1:]:\n",
    "    removes = single_comment.find_all(\"span\", class_=\"poster\")\n",
    "    for remove in removes:\n",
    "        remove.extract()\n",
    "    removes = single_comment.find_all(\"blockquote\")\n",
    "    for remove in removes:\n",
    "        remove.extract()\n",
    "    author = single_comment.find(\"div\", class_=\"single-post-author group\").find(\"div\", class_=\"fn\").text\n",
    "    content = single_comment.find(\"div\", class_=\"single-post-content\").text.replace(\"\\n\",\"\").replace(\"\\r\",\"\").replace(\" \",\"\")\n",
    "    content = author + \":\" + content\n",
    "    comment.append(content)\n",
    "                                                                                                     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment(soup):\n",
    "    comment = []\n",
    "    for single_comment in soup.find_all(\"article\")[1:]:\n",
    "        removes = single_comment.find_all(\"span\", class_=\"poster\")\n",
    "        for remove in removes:\n",
    "            remove.extract()\n",
    "        removes = single_comment.find_all(\"blockquote\")\n",
    "        for remove in removes:\n",
    "            remove.extract()\n",
    "        author = single_comment.find(\"div\", class_=\"single-post-author group\").find(\"div\", class_=\"fn\").text\n",
    "        content = single_comment.find(\"div\", class_=\"single-post-content\").text.replace(\"\\n\",\"\").replace(\"\\r\",\"\").replace(\" \",\"\")\n",
    "        content = author + \":\" + content\n",
    "        comment.append(content)\n",
    "    \n",
    "    return comment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment_p2(soup):\n",
    "    comment = []\n",
    "    for single_comment in soup.find_all(\"article\"):\n",
    "        removes = single_comment.find_all(\"span\", class_=\"poster\")\n",
    "        for remove in removes:\n",
    "            remove.extract()\n",
    "        removes = single_comment.find_all(\"blockquote\")\n",
    "        for remove in removes:\n",
    "            remove.extract()\n",
    "        author = single_comment.find(\"div\", class_=\"single-post-author group\").find(\"div\", class_=\"fn\").text\n",
    "        content = single_comment.find(\"div\", class_=\"single-post-content\").text.replace(\"\\n\",\"\").replace(\"\\r\",\"\").replace(\" \",\"\")\n",
    "        content = author + \":\" + content\n",
    "        comment.append(content)\n",
    "    \n",
    "    return comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art = BeautifulSoup(get_connect(\"https://www.mobile01.com/waypointtopicdetail.php?f=195&t=5694705#2\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = art.find_all(\"div\",class_=\"pagination\")[1].find_all(\"a\")\n",
    "for link in links:\n",
    "    if link.find(string=re.compile(\"下一頁\")):\n",
    "        print(link)\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# stackoverflow solution \n",
    "# https://stackoverflow.com/questions/31958637/beautifulsoup-search-by-text-inside-a-tag\n",
    "art2 = BeautifulSoup(get_connect(\"https://www.mobile01.com/waypointtopicdetail.php?f=189&t=4462255\").text)\n",
    "links = art2.find_all(\"div\",class_=\"pagination\")[1].find_all(\"a\")\n",
    "for link in links :\n",
    "    if link.find(string=re.compile(\"下一頁\")):\n",
    "        print(\"https://www.mobile01.com/\"+link[\"href\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.compile(\"下一頁 ›\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = BeautifulSoup(get_connect(\"https://www.ptt.cc/bbs/Food/M.1523617167.A.44E.html\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if resp.find_all(\"div\", class_=\"push\"):\n",
    "    print(\"A\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
