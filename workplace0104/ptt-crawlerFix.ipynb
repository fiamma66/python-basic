{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare packages\n",
    "import requests, pandas as pd\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "# from pythonjsonlogger import jsonlogger\n",
    "import logmatic\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import time, random\n",
    "# 現狀 抓2~10頁 並塞入DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mongoDB Connector\n",
    "from Mongo_account import MongoBase\n",
    "\n",
    "mongo = MongoBase(\"test3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo.collection.find({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 設定現在時間 以時間來作為log檔名 一個log 以日計算\n",
    "# 並在當下目錄創建 log folder\n",
    "def get_time():\n",
    "    now = datetime.utcnow()\n",
    "    path = \"./log\"\n",
    "\n",
    "    utc_8 = timezone(timedelta(hours=8))\n",
    "    now = now.replace(tzinfo=timezone.utc)\n",
    "\n",
    "    time_now = now.astimezone(utc_8)\n",
    "\n",
    "    split = str(time_now).split(\" \")\n",
    "    file_date = split[0]\n",
    "    split = split[1].split(\":\")\n",
    "    file_time = split[0]+split[1]\n",
    "    if not os.path.exists(path) :\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    return path + \"/\" + file_date \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory\n",
    "#url = \"https://www.ptt.cc/bbs/Food/index2.html\"\n",
    "\n",
    "# set proxy to use\n",
    "proxylist = [{\"http\": \"37.187.120.123:80\"},\n",
    "             {\"https\": \"206.189.36.198:8080\"},\n",
    "             {\"https\": \"178.128.31.153:8080\"},\n",
    "             {\"http\": \"167.114.180.102:8080\"},\n",
    "             {\"http\": \"104.131.214.218:80\"},\n",
    "             {\"http\": \"167.114.196.153:80\"}]\n",
    "header = {'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example use of logmatic \n",
    "# more simple \n",
    "\n",
    "logger = logging.getLogger()\n",
    " \n",
    "handler = logging.FileHandler(get_time())\n",
    "handler.setFormatter(logmatic.JsonFormatter())\n",
    " \n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 製作 url List\n",
    "def get_url(n=2,m=3):\n",
    "    result = []\n",
    "    # 增加直覺 從第n頁 到 第m頁\n",
    "    m = m + 1\n",
    "    for t in range(n,m):\n",
    "        url = \"https://www.ptt.cc/bbs/Food/index\" + str(t) + \".html\"\n",
    "        result.append(url)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 連線流程\n",
    "def get_connect(url):\n",
    "    i = 0\n",
    "    resp = \"\"\n",
    "    try :\n",
    "        resp = requests.get(url,headers=header,proxies=proxylist[i])\n",
    "        resp.encoding = \"utf-8\"\n",
    "        time.sleep(random.randint(1,4))\n",
    "        # 設定連線狀況 log\n",
    "        code = \"HTTP response code = \" + str(resp.status_code)\n",
    "        logger.info(code,extra={\"url\" : url, \"time_use\" : resp.elapsed.total_seconds()})\n",
    "        while resp.status_code != 200 :\n",
    "            logger.info(\"Connect error\",extra={\"url\" : url, \"http response\": resp.raise_for_status()})\n",
    "            resp.close()\n",
    "            i = (i + 1) % 6\n",
    "            resp = requests.get(url,headers=header,proxies=proxylist[i])\n",
    "            resp.encoding = \"utf-8\"\n",
    "\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(e,exc_info=True)\n",
    "    \n",
    "    return resp.text \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(urls):\n",
    "# 進入ptt列表 抓取 標題、推文數、網址 \n",
    "    result = []\n",
    "    soup = BeautifulSoup(get_connect(urls))\n",
    "    print(\"進入ptt : \",urls)\n",
    "    post = soup.find_all(\"div\", class_=\"r-ent\")\n",
    "    for r in post:\n",
    "        # 記憶區 保平安用\n",
    "        # 多次調用條件中的值\n",
    "        # 有時會出錯\n",
    "        article = []\n",
    "        href = \"\"\n",
    "        title = \"\"\n",
    "        author = \"\"\n",
    "        title_in_content = \"\"\n",
    "        date_in_content = \"\"\n",
    "        pos = []\n",
    "        neg = []\n",
    "        arrow = []\n",
    "        score = 0\n",
    "        content = \"\"\n",
    "        # 取得推的數量\n",
    "        push = 0\n",
    "        if r.find(\"div\", class_=\"nrec\").text:\n",
    "            try:\n",
    "                push = int(r.find(\"div\", class_=\"nrec\").text)\n",
    "            except ValueError:\n",
    "                    pass\n",
    "        if r.find(\"a\"):\n",
    "            # 取得網址\n",
    "            href = \"http://www.ptt.cc\" + r.find(\"a\")[\"href\"]\n",
    "            # 取得標題\n",
    "            title = r.find(\"a\").text\n",
    "\n",
    "            # 進入第二層 進入每一篇\n",
    "            # 去除公告 請益 為分類的文章\n",
    "            if not \"公告\" in title :\n",
    "                if not \"請益\" in title:\n",
    "                    print(\"現在處理: \", href)\n",
    "                    art = BeautifulSoup(get_connect(href))\n",
    "                    \n",
    "                    content = art.find(\"div\", id=\"main-content\")\n",
    "                    # 保存要丟棄的資訊\n",
    "                    val = content.find_all(\"span\", {\"class\":\"article-meta-value\"})\n",
    "                    #  文章排版問題 有些文章沒有部份以下資訊\n",
    "                    try:\n",
    "                        author = val[0].text\n",
    "                        title_in_content = val[2].text\n",
    "                        date_in_content = val[3].text\n",
    "                    except IndexError as e:\n",
    "                        logger.warning(\"article span list out of index\", extra = {\"url\" : href})\n",
    "                        pass\n",
    "\n",
    "                    # 開始丟棄資訊\n",
    "                    removes = content.find_all(\"div\", class_=\"article-metaline\")\n",
    "                    for remove in removes:\n",
    "                        remove.extract()\n",
    "                    removes = content.find_all(\"div\", class_=\"article-metaline-right\")\n",
    "                    for remove in removes:\n",
    "                        remove.extract()\n",
    "                    removes = content.find_all(\"span\", class_=\"f2\")                    \n",
    "                    for remove in removes:\n",
    "                        if \"※\" in remove.text:\n",
    "                            remove.extract()\n",
    "                    # 處理推噓文\n",
    "                    ps = content.find_all(\"div\", class_=\"push\")\n",
    "                    for p in ps:\n",
    "                        tag = p.find(\"span\", class_=\"push-tag\").text\n",
    "                        if \"推\" in tag:\n",
    "                            score = score + 1\n",
    "                            # replace 第三個參數 只置換第一個\n",
    "                            #push_content = p.find(\"span\", class_=\"push-content\").text.replace(\": \",\"\",1)\n",
    "                            push_content = p.find(\"span\", class_=\"push-content\").text\n",
    "                            push_ID = p.find(\"span\", class_=\"push-userid\").text\n",
    "                            push_total = push_ID + push_content\n",
    "                            pos.append(push_total)\n",
    "                        elif \"噓\" in tag:\n",
    "                            score = score - 1\n",
    "                            push_content = p.find(\"span\", class_=\"push-content\").text\n",
    "                            push_ID = p.find(\"span\", class_=\"push-userid\").text\n",
    "                            push_total = push_ID + push_content\n",
    "                            neg.append(push_total)\n",
    "                        else :\n",
    "                            push_content = p.find(\"span\", class_=\"push-content\").text\n",
    "                            push_ID = p.find(\"span\", class_=\"push-userid\").text\n",
    "                            push_total = push_ID + push_content\n",
    "                            arrow.append(push_total)\n",
    "                        p.extract()\n",
    "                    #article.append({\n",
    "                    #    \"author\" : author,\n",
    "                    #    \"title_in_content\" : title_in_content,\n",
    "                    #    \"date_in_content\" : date_in_content,                        \n",
    "                    #    \"content\" : content.text,\n",
    "                    #    \"score\" : score,\n",
    "                    #    \"推文\" : pos,\n",
    "                    #    \"噓文\" : neg                        \n",
    "                    #})\n",
    "\n",
    "        result.append({\n",
    "            \"title\" : title,\n",
    "            \"author\" : author,\n",
    "            \"date\" : date_in_content,\n",
    "            \"push\" : push,\n",
    "            \"href\" : href,\n",
    "            \"content\" : content.text,\n",
    "            \"score\" : score,\n",
    "            \"推文\" : pos,\n",
    "            \"噓文\" : neg,\n",
    "            \"箭頭\" : arrow\n",
    "            \n",
    "\n",
    "        })\n",
    "        \n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, wait, ProcessPoolExecutor, as_completed\n",
    "\n",
    "new_result = []\n",
    "with ProcessPoolExecutor(max_workers= 5) as executor:\n",
    "    future_result = {executor.submit(parse, url) : url for url in get_url(2,5)}\n",
    "\n",
    "    \n",
    "\n",
    "    for future in as_completed(future_result):\n",
    "        new_result.append(future.result())\n",
    "        print(\"work has done\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=[\"title\",\"author\",\"date\",\"push\",\"href\",\"content\",\"score\",\"推文\",\"噓文\",\"箭頭\"])\n",
    "for r in new_result:\n",
    "    for evey in r:\n",
    "        s = pd.Series([evey[\"title\"],evey[\"author\"],evey[\"date\"],evey[\"push\"],evey[\"href\"],evey[\"content\"],evey[\"score\"],evey[\"推文\"],evey[\"噓文\"],evey[\"箭頭\"]]\n",
    "                      ,index=[\"title\",\"author\",\"date\",\"push\",\"href\",\"content\",\"score\",\"推文\",\"噓文\",\"箭頭\"])\n",
    "        df = df.append(s,ignore_index=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "collect = json.loads(df.T.to_json()).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "class MongoBase:\n",
    "    def __init__(self,collection):\n",
    "        self.collection=collection\n",
    "        self.OpenDB()\n",
    "    def OpenDB(self):\n",
    "        user='root'\n",
    "        passwd='root'\n",
    "        # on local host\n",
    "        host='192.168.114.130'\n",
    "        port='27017'\n",
    "        auth_db='admin'\n",
    "        uri = \"mongodb://\"+user+\":\"+passwd+\"@\"+host+\":\"+port+\"/\"+auth_db+\"?authMechanism=SCRAM-SHA-1\"\n",
    "        self.con = MongoClient(uri, connect=True)\n",
    "        self.db=self.con['wangdong']\n",
    "        self.collection=self.db[self.collection]\n",
    "    def closeDB(self):\n",
    "        self.con.close()\n",
    "        \n",
    "mongo = MongoBase('test3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mongo.collection.insert_many(collect)\n",
    "mongo.closeDB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 進入ptt列表 抓取 標題、推文數、網址 \n",
    "result = []\n",
    "soup = BeautifulSoup(get_connect(url))\n",
    "print(\"進入ptt : \",url)\n",
    "post = soup.find_all(\"div\", class_=\"r-ent\")\n",
    "for r in post:\n",
    "            # 取得推的數量\n",
    "    push = 0\n",
    "    if r.find(\"div\", class_=\"nrec\").text:\n",
    "        try:\n",
    "            push = int(r.find(\"div\", class_=\"nrec\").text)\n",
    "        except ValueError:\n",
    "                pass\n",
    "    if r.find(\"a\"):\n",
    "        # 取得網址\n",
    "        href = \"http://www.ptt.cc\" + r.find(\"a\")[\"href\"]\n",
    "        # 取得標題\n",
    "        title = r.find(\"a\").text\n",
    "        \n",
    "        # 進入第二層 進入每一篇\n",
    "        # 去除公告 請益 為分類的文章\n",
    "        if not \"公告\" in title :\n",
    "            if not \"請益\" in title:\n",
    "                print(\"現在處理: \", href)\n",
    "                art = BeautifulSoup(get_connect(href))\n",
    "                article = []\n",
    "                content = art.find(\"div\", id=\"main-content\")\n",
    "                # 保存要丟棄的資訊\n",
    "                val = content.find_all(\"span\", {\"class\":\"article-meta-value\"})\n",
    "                author = val[0].text\n",
    "                title_in_content = val[2].text\n",
    "                date_in_content = val[3].text\n",
    "                \n",
    "                # 開始丟棄資訊\n",
    "                removes = content.find_all(\"div\", class_=\"article-metaline\")\n",
    "                for remove in removes:\n",
    "                    remove.extract()\n",
    "                removes = content.find_all(\"div\", class_=\"article-metaline-right\")\n",
    "                for remove in removes:\n",
    "                    remove.extract()\n",
    "                removes = content.find_all(\"span\", class_=\"f2\")\n",
    "                for remove in removes:\n",
    "                    remove.extract()\n",
    "                removes = content.find_all(\"div\", class_=\"push\")\n",
    "                for remove in removes:\n",
    "                    remove.extract()\n",
    "                article.append({\n",
    "                    \"author\" : author,\n",
    "                    \"title_in_content\" : title_in_content,\n",
    "                    \"date_in_content\" : date_in_content,\n",
    "                    \"content\" : content.text\n",
    "                })\n",
    "                \n",
    "    result.append({\n",
    "        \"title\" : title,\n",
    "        \"push\" : push,\n",
    "        \"href\" : href,\n",
    "        \"content\" : article\n",
    "        \n",
    "    })\n",
    "    \n",
    "    time.sleep(random.randint(1,6))\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# 轉成 Dataframe\n",
    "df = pd.DataFrame(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 排列欄位順序\n",
    "\n",
    "df = df[ [\"title\", \"push\", \"href\", \"content\" ] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O 較多 使用 thread\n",
    "start = time.time()\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "    results = executor.map(int, ['1', '2', '3', '4', '5'])\n",
    "    for v in results:\n",
    "        print(v)\n",
    "end = time.time()\n",
    "print(\"time used :\",end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example use of json_logging\n",
    "# more detail\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "import json_logging\n",
    "\n",
    "# log is initialized without a web framework name\n",
    "json_logging.ENABLE_JSON_LOGGING = True\n",
    "json_logging.init()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "#logger.info(\"test log statement\")\n",
    "#logger.info(\"test log statement\", extra={'props': {\"extra_property\": 'extra_value'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set logging \n",
    "# 設定 log config \n",
    "# less detail\n",
    "\n",
    "handler = logging.FileHandler(get_time())  # Or FileHandler or anything else\n",
    "# Configure the fields to include in the JSON output. message is the main log string itself\n",
    "format_str = '%(message)%(levelname)%(name)%(asctime)'\n",
    "formatter = jsonlogger.JsonFormatter(format_str)\n",
    "handler.setFormatter(formatter)\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.addHandler(handler)\n",
    "logger.setLevel(logging.INFO)\n",
    "# Normally we would attach the handler to the root logger, and this would be unnecessary\n",
    "logger.propagate = False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
